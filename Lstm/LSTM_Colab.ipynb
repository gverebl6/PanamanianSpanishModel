{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gx9nQpzJOfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d36bcab-759c-4022-beb7-3a702b151925"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer #Importar liberias necesarias\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import re,os\n",
        "from keras.utils import to_categorical\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtLZIDimJTCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "67b3626e-e12c-4e06-f4e5-8b87b3f1c0f8"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/txt_tesis/txts_extracted.zip \\\n",
        " -O /tmp/files.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-22 12:03:34--  https://storage.googleapis.com/txt_tesis/txts_extracted.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 108.177.13.128, 172.217.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2887953 (2.8M) [application/zip]\n",
            "Saving to: ‘/tmp/files.zip’\n",
            "\n",
            "/tmp/files.zip      100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-09-22 12:03:35 (107 MB/s) - ‘/tmp/files.zip’ saved [2887953/2887953]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUkvayJVJePc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75b604e1-4632-4963-bca9-1fb4756df4eb"
      },
      "source": [
        "!unzip /tmp/files.zip -d /tmp/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /tmp/files.zip\n",
            "   creating: /tmp/txt_tesis/\n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_21_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_04_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_15_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_23_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_18_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_29_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_10_24_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_22_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_05_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_18_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_30_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_03_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_12_04_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_23_a_comi_trabajo.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_28_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_24_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_30_a_comi_poblacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_23_a_comi_familia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_14_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_15_a_comi_poblacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_24_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_09_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_12_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_17_a_comi_presupuesto.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_25_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_11_13_a_comi_comercio.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_01_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_28_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_10_10_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_22_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_22_a_comi_municipales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_21_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_18_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_18_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_06_a_comi_poblacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_26_a_comi_relaciones.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_11_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_19_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_20_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_04_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_26_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_16_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_10_a_comi_relaciones.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_31_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_16_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_14_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_22_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_01_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_16_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_11_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_16_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_11_27_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_02_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_01_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_19_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_19_a_comi_municipales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_06_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_03_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_09_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_27_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_29_a_comi_familia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_29_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_05_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_13_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_23_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_07_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_08_a_comi_municipales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_10_29_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_02_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_25_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_14_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_23_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_24_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_18_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_28_a_comi_municipales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_31_a_comi_trabajo.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_07_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_17_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_05_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_22_a_comi_comercio.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_21_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_17_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_07_a_comi_familia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_11_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_31_a_comi_relaciones.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_02_v_comi_comercio.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_25_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_29_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_08_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_30_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_10_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_15_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_30_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_29_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_10_08_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_03_a_comi_comercio.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_08_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_02_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_01_a_comi_familia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_24_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_11_26_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_31_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_01_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_31_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_09_19_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_21_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_24_a_comi_indigena.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_26_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_11_20_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_13_a_comi_comercio.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_27_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_08_a_comi_relaciones.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_06_a_comi_trabajo.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_12_02_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_06_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_03_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_12_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_02_11_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_14_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_18_b_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_07_16_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_12_11_a_comi_poblacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_16_a_comi_relaciones.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_12_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_01_29_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_03_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_12_02_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_27_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_10_a_comi_canal.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2020_02_06_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_09_03_a_comi_trabajo.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_07_31_a_comi_comunicacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_14_a_comi_familia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_06_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_07_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_08_14_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_30_a_comi_educacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_24_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_12_17_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_10_30_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_10_30_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_20_a_comi_poblacion.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_07_a_comi_credenciales.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_07_a_comi_justicia.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_pleno_2019_11_25_a_pleno.txt  \n",
            "  inflating: /tmp/txt_tesis/acta_comision_2019_08_26_a_comi_credenciales.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yq1lpjdJhQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataPath='/tmp/txt_tesis/'\n",
        "data=''"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIo2XL2aJsst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txtNames=[]\n",
        "\n",
        "for txtName in os.listdir(dataPath):\n",
        "    txtNames.append(txtName)\n",
        "    \n",
        "i=0\n",
        "for txtName in txtNames:\n",
        "    txtFile=open(dataPath+txtName)\n",
        "    txtFile.seek(0)\n",
        "    if(i<=18):\n",
        "      data=data+txtFile.read()\n",
        "    i=i+1\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLvxzYRaKG-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7b8b9b4-e544-4fac-90cd-4c9ee86ad030"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1254353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoOwDDwTKPbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned = re.sub(r'\\W+', ' ', data).lower()\n",
        "tokens = word_tokenize(cleaned)\n",
        "train_len = 3+1\n",
        "text_sequences = []\n",
        "for i in range(train_len,len(tokens)):\n",
        "    seq = tokens[i-train_len:i]\n",
        "    text_sequences.append(seq)\n",
        "\n",
        "sequences = {}\n",
        "count = 1\n",
        "\n",
        "for i in range(len(tokens)):\n",
        "    if tokens[i] not in sequences:\n",
        "        sequences[tokens[i]] = count\n",
        "        count += 1\n",
        "        \n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences) \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgqw0j76Klhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)+1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Fn_7sTMAtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
        "for i in range(len(sequences)):\n",
        "    n_sequences[i] = sequences[i]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FncYrwuKMRjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = n_sequences[:,:-1]\n",
        "train_targets = n_sequences[:,-1]\n",
        "train_targets = to_categorical(train_targets, num_classes=vocabulary_size)\n",
        "seq_len = train_inputs.shape[1]\n",
        "#train_inputs.shape\n",
        "#print(train_targets[0])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7liTYvYZVxrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"nextword1.h5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto')\n",
        "\n",
        "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
        "\n",
        "logdir='logsnextword1'\n",
        "tensorboard_Visualization = TensorBoard(log_dir=logdir)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3ab5V00MTyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8142e9b-cd9d-48bd-eae8-6c9fdc2827b2"
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "#model = load_model(\"mymodel.h5\")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile network\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_inputs,train_targets,epochs=50,verbose=1,callbacks=[checkpoint, reduce, tensorboard_Visualization])\n",
        "model.save(\"nextword1.h5\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 3, 3)              39834     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 3, 50)             10800     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13278)             677178    \n",
            "=================================================================\n",
            "Total params: 750,562\n",
            "Trainable params: 750,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "   1/6289 [..............................] - ETA: 0s - loss: 9.4939 - accuracy: 0.0000e+00WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "   2/6289 [..............................] - ETA: 4:04 - loss: 9.4936 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0291s vs `on_train_batch_end` time: 0.0478s). Check your callbacks.\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 6.6631 - accuracy: 0.0722\n",
            "Epoch 00001: loss improved from inf to 6.66313, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 117s 19ms/step - loss: 6.6631 - accuracy: 0.0722\n",
            "Epoch 2/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 6.0958 - accuracy: 0.1020\n",
            "Epoch 00002: loss improved from 6.66313 to 6.09580, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 116s 18ms/step - loss: 6.0958 - accuracy: 0.1020\n",
            "Epoch 3/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 5.7127 - accuracy: 0.1259\n",
            "Epoch 00003: loss improved from 6.09580 to 5.71290, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 114s 18ms/step - loss: 5.7129 - accuracy: 0.1259\n",
            "Epoch 4/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 5.4086 - accuracy: 0.1439\n",
            "Epoch 00004: loss improved from 5.71290 to 5.40860, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 5.4086 - accuracy: 0.1439\n",
            "Epoch 5/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 5.1852 - accuracy: 0.1563\n",
            "Epoch 00005: loss improved from 5.40860 to 5.18519, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 115s 18ms/step - loss: 5.1852 - accuracy: 0.1563\n",
            "Epoch 6/50\n",
            "6289/6289 [==============================] - ETA: 0s - loss: 5.0216 - accuracy: 0.1665\n",
            "Epoch 00006: loss improved from 5.18519 to 5.02159, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 114s 18ms/step - loss: 5.0216 - accuracy: 0.1665\n",
            "Epoch 7/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.8961 - accuracy: 0.1733\n",
            "Epoch 00007: loss improved from 5.02159 to 4.89601, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 4.8960 - accuracy: 0.1733\n",
            "Epoch 8/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.7966 - accuracy: 0.1796\n",
            "Epoch 00008: loss improved from 4.89601 to 4.79665, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 4.7967 - accuracy: 0.1796\n",
            "Epoch 9/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.7143 - accuracy: 0.1847\n",
            "Epoch 00009: loss improved from 4.79665 to 4.71443, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 112s 18ms/step - loss: 4.7144 - accuracy: 0.1847\n",
            "Epoch 10/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.6444 - accuracy: 0.1893\n",
            "Epoch 00010: loss improved from 4.71443 to 4.64436, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 112s 18ms/step - loss: 4.6444 - accuracy: 0.1893\n",
            "Epoch 11/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 4.5826 - accuracy: 0.1932\n",
            "Epoch 00011: loss improved from 4.64436 to 4.58264, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.5826 - accuracy: 0.1932\n",
            "Epoch 12/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.5284 - accuracy: 0.1962\n",
            "Epoch 00012: loss improved from 4.58264 to 4.52842, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.5284 - accuracy: 0.1962\n",
            "Epoch 13/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.4814 - accuracy: 0.2000\n",
            "Epoch 00013: loss improved from 4.52842 to 4.48139, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.4814 - accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 4.4384 - accuracy: 0.2022\n",
            "Epoch 00014: loss improved from 4.48139 to 4.43844, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 4.4384 - accuracy: 0.2022\n",
            "Epoch 15/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.4008 - accuracy: 0.2046\n",
            "Epoch 00015: loss improved from 4.43844 to 4.40085, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 106s 17ms/step - loss: 4.4009 - accuracy: 0.2046\n",
            "Epoch 16/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.3660 - accuracy: 0.2069\n",
            "Epoch 00016: loss improved from 4.40085 to 4.36604, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.3660 - accuracy: 0.2069\n",
            "Epoch 17/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.3343 - accuracy: 0.2089\n",
            "Epoch 00017: loss improved from 4.36604 to 4.33430, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 108s 17ms/step - loss: 4.3343 - accuracy: 0.2089\n",
            "Epoch 18/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.3036 - accuracy: 0.2104\n",
            "Epoch 00018: loss improved from 4.33430 to 4.30359, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 109s 17ms/step - loss: 4.3036 - accuracy: 0.2104\n",
            "Epoch 19/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.2729 - accuracy: 0.2127\n",
            "Epoch 00019: loss improved from 4.30359 to 4.27289, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 106s 17ms/step - loss: 4.2729 - accuracy: 0.2127\n",
            "Epoch 20/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.2455 - accuracy: 0.2145\n",
            "Epoch 00020: loss improved from 4.27289 to 4.24550, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 108s 17ms/step - loss: 4.2455 - accuracy: 0.2145\n",
            "Epoch 21/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.2188 - accuracy: 0.2150\n",
            "Epoch 00021: loss improved from 4.24550 to 4.21882, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 4.2188 - accuracy: 0.2150\n",
            "Epoch 22/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 4.1953 - accuracy: 0.2175\n",
            "Epoch 00022: loss improved from 4.21882 to 4.19526, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 108s 17ms/step - loss: 4.1953 - accuracy: 0.2175\n",
            "Epoch 23/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.1728 - accuracy: 0.2188\n",
            "Epoch 00023: loss improved from 4.19526 to 4.17279, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 4.1728 - accuracy: 0.2188\n",
            "Epoch 24/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.1523 - accuracy: 0.2201\n",
            "Epoch 00024: loss improved from 4.17279 to 4.15224, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 4.1522 - accuracy: 0.2201\n",
            "Epoch 25/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.1318 - accuracy: 0.2218\n",
            "Epoch 00025: loss improved from 4.15224 to 4.13184, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.1318 - accuracy: 0.2218\n",
            "Epoch 26/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.1131 - accuracy: 0.2232\n",
            "Epoch 00026: loss improved from 4.13184 to 4.11309, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.1131 - accuracy: 0.2232\n",
            "Epoch 27/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.0971 - accuracy: 0.2245\n",
            "Epoch 00027: loss improved from 4.11309 to 4.09709, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 105s 17ms/step - loss: 4.0971 - accuracy: 0.2245\n",
            "Epoch 28/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.0808 - accuracy: 0.2254\n",
            "Epoch 00028: loss improved from 4.09709 to 4.08087, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 106s 17ms/step - loss: 4.0809 - accuracy: 0.2254\n",
            "Epoch 29/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.0661 - accuracy: 0.2261\n",
            "Epoch 00029: loss improved from 4.08087 to 4.06607, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 4.0661 - accuracy: 0.2261\n",
            "Epoch 30/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 4.0505 - accuracy: 0.2279\n",
            "Epoch 00030: loss improved from 4.06607 to 4.05050, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 4.0505 - accuracy: 0.2279\n",
            "Epoch 31/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.0377 - accuracy: 0.2290\n",
            "Epoch 00031: loss improved from 4.05050 to 4.03772, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 110s 17ms/step - loss: 4.0377 - accuracy: 0.2290\n",
            "Epoch 32/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.0247 - accuracy: 0.2299\n",
            "Epoch 00032: loss improved from 4.03772 to 4.02472, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 109s 17ms/step - loss: 4.0247 - accuracy: 0.2299\n",
            "Epoch 33/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 4.0124 - accuracy: 0.2310\n",
            "Epoch 00033: loss improved from 4.02472 to 4.01243, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 109s 17ms/step - loss: 4.0124 - accuracy: 0.2310\n",
            "Epoch 34/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 4.0011 - accuracy: 0.2321\n",
            "Epoch 00034: loss improved from 4.01243 to 4.00111, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 4.0011 - accuracy: 0.2320\n",
            "Epoch 35/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 3.9899 - accuracy: 0.2332\n",
            "Epoch 00035: loss improved from 4.00111 to 3.99000, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 3.9900 - accuracy: 0.2332\n",
            "Epoch 36/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 3.9786 - accuracy: 0.2338\n",
            "Epoch 00036: loss improved from 3.99000 to 3.97871, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 114s 18ms/step - loss: 3.9787 - accuracy: 0.2338\n",
            "Epoch 37/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 3.9679 - accuracy: 0.2354\n",
            "Epoch 00037: loss improved from 3.97871 to 3.96800, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 115s 18ms/step - loss: 3.9680 - accuracy: 0.2354\n",
            "Epoch 38/50\n",
            "6289/6289 [==============================] - ETA: 0s - loss: 3.9585 - accuracy: 0.2360\n",
            "Epoch 00038: loss improved from 3.96800 to 3.95850, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 114s 18ms/step - loss: 3.9585 - accuracy: 0.2360\n",
            "Epoch 39/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 3.9493 - accuracy: 0.2366\n",
            "Epoch 00039: loss improved from 3.95850 to 3.94933, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 3.9493 - accuracy: 0.2366\n",
            "Epoch 40/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 3.9406 - accuracy: 0.2371\n",
            "Epoch 00040: loss improved from 3.94933 to 3.94047, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 115s 18ms/step - loss: 3.9405 - accuracy: 0.2372\n",
            "Epoch 41/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 3.9315 - accuracy: 0.2387\n",
            "Epoch 00041: loss improved from 3.94047 to 3.93152, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 114s 18ms/step - loss: 3.9315 - accuracy: 0.2387\n",
            "Epoch 42/50\n",
            "6289/6289 [==============================] - ETA: 0s - loss: 3.9235 - accuracy: 0.2389\n",
            "Epoch 00042: loss improved from 3.93152 to 3.92353, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 3.9235 - accuracy: 0.2389\n",
            "Epoch 43/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 3.9146 - accuracy: 0.2394\n",
            "Epoch 00043: loss improved from 3.92353 to 3.91464, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 114s 18ms/step - loss: 3.9146 - accuracy: 0.2394\n",
            "Epoch 44/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 3.9077 - accuracy: 0.2405\n",
            "Epoch 00044: loss improved from 3.91464 to 3.90762, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 112s 18ms/step - loss: 3.9076 - accuracy: 0.2405\n",
            "Epoch 45/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 3.8995 - accuracy: 0.2411\n",
            "Epoch 00045: loss improved from 3.90762 to 3.89947, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 3.8995 - accuracy: 0.2411\n",
            "Epoch 46/50\n",
            "6287/6289 [============================>.] - ETA: 0s - loss: 3.8923 - accuracy: 0.2425\n",
            "Epoch 00046: loss improved from 3.89947 to 3.89223, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 3.8922 - accuracy: 0.2425\n",
            "Epoch 47/50\n",
            "6286/6289 [============================>.] - ETA: 0s - loss: 3.8863 - accuracy: 0.2426\n",
            "Epoch 00047: loss improved from 3.89223 to 3.88627, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 113s 18ms/step - loss: 3.8863 - accuracy: 0.2426\n",
            "Epoch 48/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 3.8780 - accuracy: 0.2436\n",
            "Epoch 00048: loss improved from 3.88627 to 3.87795, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 110s 17ms/step - loss: 3.8780 - accuracy: 0.2436\n",
            "Epoch 49/50\n",
            "6288/6289 [============================>.] - ETA: 0s - loss: 3.8719 - accuracy: 0.2442\n",
            "Epoch 00049: loss improved from 3.87795 to 3.87197, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 109s 17ms/step - loss: 3.8720 - accuracy: 0.2442\n",
            "Epoch 50/50\n",
            "6289/6289 [==============================] - ETA: 0s - loss: 3.8648 - accuracy: 0.2443\n",
            "Epoch 00050: loss improved from 3.87197 to 3.86482, saving model to nextword1.h5\n",
            "6289/6289 [==============================] - 107s 17ms/step - loss: 3.8648 - accuracy: 0.2443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDRqiFRzV-NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "model = load_model(\"nextword1.h5\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sjxd0X9C8DP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "015721d3-9c8e-46ae-dfae-21b967b67f0a"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "input_text = input().strip().lower()\n",
        "encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "print(encoded_text, pad_encoded)\n",
        "for i in (model.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
        "  pred_word = tokenizer.index_word[i]\n",
        "  print(\"Next word suggestion:\",pred_word)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "En cuanto a\n",
            "[7, 349, 6] [[  7 349   6]]\n",
            "Next word suggestion: la\n",
            "Next word suggestion: los\n",
            "Next word suggestion: una\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb__FJnpC-We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}